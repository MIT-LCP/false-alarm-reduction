{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime                      import datetime\n",
    "import invalid_sample_detection    as invalid\n",
    "import evaluation                  as evaluate\n",
    "import load_annotations            as annotate\n",
    "import regular_activity            as regular\n",
    "import specific_arrhythmias        as arrhythmia\n",
    "import numpy                       as np\n",
    "import parameters\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import wfdb\n",
    "\n",
    "data_path = 'sample_data/challenge_training_data/'\n",
    "ann_path = 'sample_data/challenge_training_multiann/'\n",
    "fp_ann_path = 'sample_data/fplesinger_data/output/'\n",
    "ecg_ann_type = 'gqrs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying arrhythmia alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returns true if alarm is classified as a true alarm\n",
    "def classify_alarm(data_path, ann_path, fp_ann_path, sample_name, ecg_ann_type, verbose=False): \n",
    "    sig, fields = wfdb.rdsamp(data_path + sample_name)\n",
    "\n",
    "    is_regular = regular.is_sample_regular(data_path, ann_path, sample_name, ecg_ann_type, should_check_nan=True)    \n",
    "    if is_regular:\n",
    "        if verbose: \n",
    "            print sample_name + \"with regular activity\"\n",
    "        return False\n",
    "    \n",
    "    alarm_type = sample_name[0]\n",
    "    if alarm_type == \"a\": \n",
    "        arrhythmia_test = arrhythmia.test_asystole\n",
    "    elif alarm_type == \"b\": \n",
    "        arrhythmia_test = arrhythmia.test_bradycardia\n",
    "    elif alarm_type == \"t\": \n",
    "        arrhythmia_test = arrhythmia.test_tachycardia\n",
    "    elif alarm_type == \"v\": \n",
    "        ann_path = fp_ann_path\n",
    "        ecg_ann_type = 'fp'\n",
    "        arrhythmia_test = arrhythmia.test_ventricular_tachycardia\n",
    "    elif alarm_type == \"f\": \n",
    "        arrhythmia_test = arrhythmia.test_ventricular_flutter_fibrillation\n",
    "    else: \n",
    "        raise Exception(\"Unknown arrhythmia alarm type\")\n",
    "    \n",
    "    try: \n",
    "        classified_true_alarm = arrhythmia_test(data_path, ann_path, sample_name, ecg_ann_type, verbose)\n",
    "        return classified_true_alarm\n",
    "\n",
    "    except Exception as e: \n",
    "        print \"sample_name: \", sample_name, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns true if alarm is a true alarm\n",
    "# Only for samples with known classification\n",
    "def is_true_alarm(data_path, sample_name): \n",
    "    sig, fields = wfdb.rdsamp(data_path + sample_name)\n",
    "    alarm_type, true_alarm = regular.check_gold_standard_classification(fields)\n",
    "    return true_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix for all samples given sample name/directory\n",
    "def generate_confusion_matrix_dir(data_path, ann_path, fp_ann_path, ecg_ann_type): \n",
    "    confusion_matrix = {\n",
    "        \"TP\": [],\n",
    "        \"FP\": [],\n",
    "        \"FN\": [],\n",
    "        \"TN\": []\n",
    "    }\n",
    "    \n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.endswith(parameters.HEADER_EXTENSION):\n",
    "            sample_name = filename.rstrip(parameters.HEADER_EXTENSION)\n",
    "            \n",
    "            true_alarm = is_true_alarm(data_path, sample_name)\n",
    "            classified_true_alarm = classify_alarm(data_path, ann_path, fp_ann_path, sample_name, ecg_ann_type)\n",
    "\n",
    "            matrix_classification = get_confusion_matrix_classification(true_alarm, classified_true_alarm)\n",
    "            confusion_matrix[matrix_classification].append(sample_name)\n",
    "            if matrix_classification == \"FN\": \n",
    "                print \"FALSE NEGATIVE: \", filename\n",
    "                \n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def get_confusion_matrix_classification(true_alarm, classified_true_alarm): \n",
    "    if true_alarm and classified_true_alarm: \n",
    "        matrix_classification = \"TP\"\n",
    "\n",
    "    elif true_alarm and not classified_true_alarm: \n",
    "        matrix_classification = \"FN\"\n",
    "\n",
    "    elif not true_alarm and classified_true_alarm: \n",
    "        matrix_classification = \"FP\"\n",
    "\n",
    "    else: \n",
    "        matrix_classification = \"TN\"\n",
    "\n",
    "    return matrix_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing and calculating counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_by_type(false_negatives): \n",
    "    counts_by_type = {}\n",
    "    for false_negative in false_negatives: \n",
    "        first = false_negative[0] \n",
    "        if first not in counts_by_type.keys(): \n",
    "            counts_by_type[first] = 0\n",
    "        counts_by_type[first] += 1\n",
    "\n",
    "    print counts_by_type\n",
    "    \n",
    "    \n",
    "def print_by_arrhythmia(confusion_matrix, arrhythmia_prefix): \n",
    "    counts_by_arrhythmia = {}\n",
    "    for classification_type in confusion_matrix.keys(): \n",
    "        sample_list = [ sample for sample in confusion_matrix[classification_type] if sample[0] == arrhythmia_prefix]\n",
    "        counts_by_arrhythmia[classification_type] = (len(sample_list), sample_list)\n",
    "\n",
    "    print counts_by_arrhythmia\n",
    "    \n",
    "def get_counts(confusion_matrix): \n",
    "    return { key : len(confusion_matrix[key]) for key in confusion_matrix.keys() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-27 15:40:51.816647\n",
      "ecg_ann_type:  gqrs  ann_path:  sample_data/challenge_training_multiann/\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "FALSE NEGATIVE:  v206s.hea\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n",
      "No annotations in specified sample range\n"
     ]
    }
   ],
   "source": [
    "def run(data_path, ann_path, filename, ecg_ann_type):\n",
    "    if ecg_ann_type == \"fp\": \n",
    "        ann_path = fp_ann_path\n",
    "    print \"ecg_ann_type: \", ecg_ann_type, \" ann_path: \", ann_path\n",
    "    \n",
    "    start = datetime.now() \n",
    "    confusion_matrix_gqrs = generate_confusion_matrix_dir(data_path, ann_path, fp_ann_path, ecg_ann_type)\n",
    "#     print \"confusion matrix: \", confusion_matrix_gqrs\n",
    "    print \"total time: \", datetime.now() - start\n",
    "    \n",
    "    with open(filename, \"w\") as f: \n",
    "        json.dump(confusion_matrix_gqrs, f)\n",
    "\n",
    "def read_json(filename): \n",
    "    with open(filename, \"r\") as f: \n",
    "        dictionary = json.load(f)\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "print datetime.now()\n",
    "write_filename = \"sample_data/pipeline_fpinvalids_vtachfpann_nancheck.json\"\n",
    "ecg_ann_type = \"gqrs\"\n",
    "run(data_path, ann_path, write_filename, ecg_ann_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GQRS\n",
      "counts:  {u'FP': 154, u'TN': 302, u'FN': 18, u'TP': 276}\n",
      "sensitivity:  0.938775510204\n",
      "specificity:  0.662280701754\n",
      "ppv:  0.641860465116\n",
      "f1:  0.762430939227\n",
      "score:  0.703163017032\n",
      "{u'a': 1, u'b': 8, u't': 2, u'v': 7}\n",
      "missed true positives:  ['b183l', 'b187l', 'b379l', 't418s', 'b494s', 'b495l', 'b497l', 'a670s', 'b672s', 't700s', 'v728s', 'b734s', 'v831l']\n",
      "missed true negatives:  ['v113l', 'v115l', 'f120s', 'f121l', 'a123l', 'v140s', 'v147l', 'v177l', 'v180s', 'v181l', 'v200s', 'v204s', 'v205l', 'v212s', 'v222s', 'v224s', 'v232s', 'v241l', 'v242s', 'v243l', 'v244s', 'v250s', 'v259l', 'v262s', 'a279l', 'v280s', 'v283l', 'v295l', 'v296s', 'v298s', 'a306s', 'v312s', 'v322s', 'v326s', 'v337l', 'v347l', 'v353l', 'v355l', 'v364s', 'v365l', 'v367l', 'v373l', 'v375l', 'v390s', 'v401l', 'v405l', 'f407l', 'f408s', 'v427l', 'v437l', 'v459l', 'v463l', 'v470s', 'v472s', 'v479l', 'v481l', 'v489l', 'v491l', 'v492s', 'v498s', 'v501l', 't504s', 'v511l', 'v513l', 'v518s', 'v519l', 'f529l', 'v531l', 'v533l', 'v535l', 'v551l', 'v552s', 'v566s', 'v569l', 'v575l', 'v581l', 'v583l', 'v598s', 'v609l', 'v611l', 'v619l', 'v633l', 'v634s', 'v640s', 'a645l', 'v658s', 'v682s', 'v687l', 'v721l', 'v725l', 'v736s', 'v738s', 'v766s', 'v767l', 'v770s', 'v775l', 'a778s', 'v791l', 'v795l', 'v804s', 'v811l', 'v814s', 'a825l', 'v843l', 'v845l', 'v846s', 'v848s']\n",
      "\n",
      "FP\n",
      "counts:  {u'FP': 103, u'TN': 353, u'FN': 34, u'TP': 260}\n",
      "sensitivity:  0.884353741497\n",
      "specificity:  0.774122807018\n",
      "ppv:  0.716253443526\n",
      "f1:  0.791476407915\n",
      "score:  0.691873589165\n",
      "{u'a': 3, u'b': 12, u't': 4, u'v': 15}\n",
      "\n",
      "FP invalids with GQRS\n",
      "counts:  {u'FP': 143, u'TN': 313, u'FN': 18, u'TP': 276}\n",
      "sensitivity:  0.938775510204\n",
      "specificity:  0.686403508772\n",
      "ppv:  0.658711217184\n",
      "f1:  0.774193548387\n",
      "score:  0.716545012165\n",
      "{u'a': 1, u'b': 8, u't': 2, u'v': 7}\n",
      "missed true positives:  ['b183l', 'b187l', 'b379l', 't418s', 'b494s', 'b495l', 'b497l', 'a670s', 'b672s', 't700s', 'v728s', 'b734s', 'v831l']\n",
      "missed true negatives:  ['v113l', 'v115l', 'f120s', 'f121l', 'a123l', 'v140s', 'v148s', 'v176s', 'v177l', 'v180s', 'v200s', 'v204s', 'v205l', 'v222s', 'v224s', 'v230s', 'v232s', 'v241l', 'v242s', 'v243l', 'v244s', 'v250s', 'v259l', 'v262s', 'a279l', 'v283l', 'v295l', 'v296s', 'v298s', 'a306s', 'v322s', 'v326s', 'v336s', 'v337l', 'v338s', 'v347l', 'v353l', 'v355l', 'v364s', 'v367l', 'v373l', 'v375l', 'v390s', 'v401l', 'v405l', 'f407l', 'f408s', 'v427l', 'v432s', 'v437l', 'v459l', 'v463l', 'v470s', 'v472s', 'v479l', 'v489l', 'v491l', 'v492s', 'v498s', 'v501l', 't504s', 'v513l', 'v518s', 'v519l', 'f529l', 'v531l', 'v533l', 'v536s', 'v551l', 'v569l', 'v581l', 'v583l', 'v598s', 'v609l', 'v633l', 'v634s', 'v640s', 'a645l', 'v658s', 'v682s', 'v687l', 'v721l', 'v725l', 'v736s', 'v766s', 'v767l', 'v770s', 'v775l', 'a778s', 'v791l', 'v795l', 'v804s', 'v814s', 'a825l', 'v843l', 'v845l', 'v846s']\n",
      "{'a': 6, 'f': 5, 't': 1, 'v': 85}\n",
      "97\n",
      "\n",
      "FP invalids with GQRS without abp test in vtach\n",
      "counts:  {u'FP': 142, u'TN': 314, u'FN': 18, u'TP': 276}\n",
      "sensitivity:  0.938775510204\n",
      "specificity:  0.688596491228\n",
      "ppv:  0.66028708134\n",
      "f1:  0.775280898876\n",
      "score:  0.717761557178\n",
      "{u'a': 1, u'b': 8, u't': 2, u'v': 7}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    print \"GQRS\"\n",
    "    gqrs_matrix = read_json(\"sample_data/pipeline_gqrs.json\")\n",
    "    counts_gqrs = get_counts(gqrs_matrix)\n",
    "    evaluate.print_stats(counts_gqrs)\n",
    "    print_by_type(gqrs_matrix['FN'])\n",
    "    \n",
    "    fplesinger_confusion_matrix = others_confusion_matrices['fplesinger-210']\n",
    "    print \"missed true positives: \", get_missed(gqrs_matrix, fplesinger_confusion_matrix, \"TP\")\n",
    "    print \"missed true negatives: \", get_missed(gqrs_matrix, fplesinger_confusion_matrix, \"TN\")\n",
    "    \n",
    "    \n",
    "    print \"\\nFP\"\n",
    "    fp_matrix = read_json(\"sample_data/pipeline_fp.json\")\n",
    "    counts_fp = get_counts(fp_matrix)\n",
    "    evaluate.print_stats(counts_fp)\n",
    "    print_by_type(fp_matrix['FN'])\n",
    "\n",
    "    \n",
    "    print \"\\nFP invalids with GQRS\"\n",
    "    fpinvalids_matrix = read_json(\"sample_data/pipeline_fpinvalids.json\")\n",
    "    counts_fpinvalids = get_counts(fpinvalids_matrix)\n",
    "    evaluate.print_stats(counts_fpinvalids)\n",
    "    print_by_type(fpinvalids_matrix['FN'])\n",
    "    \n",
    "    missed_true_negatives = get_missed(fpinvalids_matrix, fplesinger_confusion_matrix, \"TN\")\n",
    "    print \"missed true positives: \", get_missed(fpinvalids_matrix, fplesinger_confusion_matrix, \"TP\")\n",
    "    print \"missed true negatives: \", missed_true_negatives\n",
    "    print_by_type(missed_true_negatives)\n",
    "    print len(missed_true_negatives)\n",
    "    \n",
    "    \n",
    "    print \"\\nFP invalids with GQRS without abp test in vtach\"\n",
    "    fpinvalids_without_vtach_abp = read_json(\"sample_data/pipeline_fpinvalids_novtachabp.json\")\n",
    "    counts_fpinvalids_without_vtach_abp = get_counts(fpinvalids_without_vtach_abp)\n",
    "    evaluate.print_stats(counts_fpinvalids_without_vtach_abp)\n",
    "    print_by_type(fpinvalids_without_vtach_abp['FN'])\n",
    "    \n",
    "#     print_by_type(gqrs_matrix['FN'])\n",
    "#     print_by_arrhythmia(confusion_matrix_gqrs, 'v')\n",
    "    \n",
    "#     fplesinger_confusion_matrix = others_confusion_matrices['fplesinger-210']\n",
    "#     print \"missed true positives: \", get_missed(gqrs_matrix, fplesinger_confusion_matrix, \"TP\")\n",
    "#     print \"missed true negatives: \", get_missed(gqrs_matrix, fplesinger_confusion_matrix, \"TN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classification with other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_others_confusion_matrices(filename, data_path): \n",
    "    others_confusion_matrices = {}\n",
    "    \n",
    "    with open(filename, \"r\") as f: \n",
    "        reader = csv.DictReader(f)\n",
    "        authors = reader.fieldnames[1:]\n",
    "        for author in authors: \n",
    "            others_confusion_matrices[author] = { \"TP\": [], \"FP\": [], \"FN\": [], \"TN\": [] }\n",
    "            \n",
    "        for line in reader: \n",
    "            sample_name = line['record name']\n",
    "            true_alarm = is_true_alarm(data_path, sample_name)\n",
    "            \n",
    "            for author in authors: \n",
    "                classified_true_alarm = line[author] == '1'\n",
    "                matrix_classification = get_confusion_matrix_classification(true_alarm, classified_true_alarm)\n",
    "                \n",
    "                others_confusion_matrices[author][matrix_classification].append(sample_name)\n",
    "    \n",
    "    return others_confusion_matrices\n",
    "                \n",
    "    \n",
    "filename = \"sample_data/answers.csv\"\n",
    "others_confusion_matrices = generate_others_confusion_matrices(filename, data_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoog.antink-216\n",
      "counts:  {'FP': 89, 'TN': 367, 'TP': 291, 'FN': 3}\n",
      "sensitivity:  0.989795918367\n",
      "specificity:  0.804824561404\n",
      "ppv:  0.765789473684\n",
      "f1:  0.86350148368\n",
      "score:  0.863517060367\n",
      "{'v': 3}\n",
      "l.m.eerikainen-209\n",
      "counts:  {'FP': 65, 'TN': 391, 'TP': 294, 'FN': 0}\n",
      "sensitivity:  1.0\n",
      "specificity:  0.857456140351\n",
      "ppv:  0.818941504178\n",
      "f1:  0.90045941807\n",
      "score:  0.913333333333\n",
      "{}\n",
      "sibylle.fallet-210\n",
      "counts:  {'FP': 108, 'TN': 348, 'TP': 276, 'FN': 18}\n",
      "sensitivity:  0.938775510204\n",
      "specificity:  0.763157894737\n",
      "ppv:  0.71875\n",
      "f1:  0.814159292035\n",
      "score:  0.759124087591\n",
      "{'b': 1, 't': 4, 'v': 13}\n",
      "vxk106120-213\n",
      "counts:  {'FP': 74, 'TN': 382, 'TP': 280, 'FN': 14}\n",
      "sensitivity:  0.952380952381\n",
      "specificity:  0.837719298246\n",
      "ppv:  0.790960451977\n",
      "f1:  0.864197530864\n",
      "score:  0.821339950372\n",
      "{'v': 14}\n",
      "fplesinger-210\n",
      "counts:  {'FP': 64, 'TN': 392, 'TP': 275, 'FN': 19}\n",
      "sensitivity:  0.93537414966\n",
      "specificity:  0.859649122807\n",
      "ppv:  0.811209439528\n",
      "f1:  0.86887835703\n",
      "score:  0.807506053269\n",
      "{'a': 1, 'f': 1, 'b': 1, 't': 1, 'v': 15}\n",
      "bestcly-204\n",
      "counts:  {'FP': 133, 'TN': 323, 'TP': 277, 'FN': 17}\n",
      "sensitivity:  0.942176870748\n",
      "specificity:  0.708333333333\n",
      "ppv:  0.675609756098\n",
      "f1:  0.786931818182\n",
      "score:  0.733496332518\n",
      "{'b': 3, 't': 1, 'v': 13}\n",
      "bellea-212\n",
      "counts:  {'FP': 327, 'TN': 129, 'TP': 291, 'FN': 3}\n",
      "sensitivity:  0.989795918367\n",
      "specificity:  0.282894736842\n",
      "ppv:  0.470873786408\n",
      "f1:  0.638157894737\n",
      "score:  0.551181102362\n",
      "{'a': 3}\n"
     ]
    }
   ],
   "source": [
    "for author in others_confusion_matrices.keys(): \n",
    "    other_confusion_matrix = others_confusion_matrices[author]\n",
    "    print author\n",
    "    counts = get_counts(other_confusion_matrix)\n",
    "    evaluate.print_stats(counts)\n",
    "    print_by_type(other_confusion_matrix['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_missed(confusion_matrix, other_confusion_matrix, classification): \n",
    "    missed = []\n",
    "    \n",
    "    for sample in other_confusion_matrix[classification]: \n",
    "        if sample not in confusion_matrix[classification]: \n",
    "            missed.append(sample)\n",
    "            \n",
    "    return missed\n",
    "    \n",
    "# fplesinger_confusion_matrix = others_confusion_matrices['fplesinger-210']\n",
    "# print \"missed true positives: \", get_missed(confusion_matrix_gqrs, fplesinger_confusion_matrix, \"TP\")\n",
    "# print \"missed true negatives: \", get_missed(confusion_matrix_gqrs, fplesinger_confusion_matrix, \"TN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
